{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "f0Rm1xJM2F4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import torchaudio\n",
        "import librosa\n",
        "from transformers import Wav2Vec2Processor, TFWav2Vec2ForCTC"
      ],
      "metadata": {
        "id": "UKlc1S0r5oNV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_audio(file_path):\n",
        "    waveform, sample_rate = torchaudio.load(file_path)\n",
        "    return waveform, sample_rate\n"
      ],
      "metadata": {
        "id": "EJy3d23Y6QQN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_audio(waveform, sample_rate):\n",
        "    waveform = waveform.numpy()\n",
        "    waveform_resampled = librosa.resample(waveform, orig_sr=sample_rate, target_sr=16000)\n",
        "    if waveform_resampled.ndim > 1:\n",
        "        waveform_resampled = librosa.to_mono(waveform_resampled)\n",
        "    waveform_resampled = tf.convert_to_tensor(waveform_resampled)\n",
        "\n",
        "    return waveform_resampled"
      ],
      "metadata": {
        "id": "OzhRqXTA6VM0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def speech_to_text(waveform):\n",
        "    processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "    model = TFWav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "    inputs = processor(waveform, sampling_rate=16000, return_tensors=\"tf\", padding=True)\n",
        "    logits = model(inputs.input_values).logits\n",
        "    predicted_ids = tf.argmax(logits, axis=-1)\n",
        "    transcription = processor.batch_decode(predicted_ids)[0]\n",
        "    return transcription"
      ],
      "metadata": {
        "id": "Ihnaqo6N6aOG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_audio_file(file_path):\n",
        "    waveform, sample_rate = load_audio(file_path)\n",
        "    waveform = preprocess_audio(waveform, sample_rate)\n",
        "    transcription = speech_to_text(waveform)\n",
        "\n",
        "    return transcription"
      ],
      "metadata": {
        "id": "YN4q2bwP6cke"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/Recording (7).m4a\"\n",
        "transcription = process_audio_file(file_path)\n",
        "print(f\"Transcription: {transcription}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znSYsvyA6ejX",
        "outputId": "60b38a0a-f05d-4e05-9dbf-9b6ee812ad7d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "TFWav2Vec2ForCTC has backpropagation operations that are NOT supported on CPU. If you wish to train/fine-tune this model, you need a GPU or a TPU\n",
            "All PyTorch model weights were used when initializing TFWav2Vec2ForCTC.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFWav2Vec2ForCTC were not initialized from the PyTorch model and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription: THIS IS AGAM PATEL SPEAKING\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9miBLreP7mIZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}